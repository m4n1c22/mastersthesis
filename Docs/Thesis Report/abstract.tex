Although silicon chip based multiprocessors have become an industry standard, developing parallel applications that target them remains a daunting task. 
Multithreaded programs are used to realize such parallel applications on these multiprocessors.
Concurrency bugs which are often resident in these multithreaded programs are difficult to find and reproduce.  
The non-deterministic nature of the multithreaded programs causes significant challenges for programmers by hindering their ability to create multithreaded programs with repeatable results. 
As a consequence, multithreaded programs are significantly harder to debug, test and maintain than sequential application. 
Thus, outlining the need for software verification techniques in multithreaded programs. 

\acrfull{dmt} is one approach used to test and debug multithreaded programs for various concurrency bugs. 
\acrshort{dmt} enforces deterministic execution on multithreaded programs by maintaining determinism in the order of executing memory events or acquiring locks. 
However, \acrshort{dmt} solutions cannot enforce a scheduling constraint on a multithreaded program and they do not control the schedule in advance. 
Thus, making \acrshort{dmt} solutions to be better regarded for concurrency testing and not verification. 
However, currently there are no such techniques that allow to control the schedule of a multithreaded program on a fine-grained level, i.e, on the level of single memory accesses. 
A design with a granularity of single memory accesses would help in enforcing the scheduling constraint. 
\acrfull{irs} is one such technique meant to satisfy the above requirement. 
The existing \acrshort{irs} framework consists of a thread scheduler, a LLVM instrumentor and a verification engine.  
The thread scheduler implemented in the existing \acrshort{irs} framework is realized in user space. 
However, there is a problem of the scheduler thread getting context switched when executed in user space. 
The operating system scheduler might ignore the scheduling constraint set by the user level scheduler. 
Moving the scheduler task to the kernel space would help to realize the safe scheduling constraints set by the user. 
This thesis focuses on moving the \acrshort{irs} thread scheduler to kernel space. 
With such a migration, we expect an improvement in the execution time when multithreaded programs are executed in the \acrshort{irs} environment.


The approach used in the thesis would be benchmarked on various benchmarking programs such as Indexer, Last Zero, Fibonacci and Dining Philosopher's Problem. 
These experiments are intended to get a better understanding of the strengths and weaknesses of the \acrshort{irs} solutions implemented in the kernel space and in the user space. 
These experiments provide a comparison between \acrshort{irs} user space and kernel space solutions with execution overhead as the evaluation metric. 
The execution overhead for each benchmark is realized by computing the overhead in execution time when the benchmark program is executed with and without scheduling constraints. 
The above experiments are also evaluated with the scaling of processor cores. 
The scaling experiments are intended to analyze the scalability of \acrshort{irs} user space and kernel space solutions. 
Such an evaluation is expected to provide some insights into various scalability problems which can reside in various \acrshort{irs} solutions. 
Additionally, we analyze the number of necessary synchronization calls made by every \acrshort{irs} kernel space solutions. 
Such an analysis is intended to study the influence of these calls on the execution overhead generated by all \acrshort{irs} kernel space solutions. 
The approach presented in this work is expected to reduce the execution overhead and also some of the shortcomings generated by its counterpart user space design. 